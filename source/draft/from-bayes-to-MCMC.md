---
title:  "从贝叶斯公式到MCMC算法"
date:   2019-12-29 21:51:23 +0800
categories: math
---

# 从贝叶斯公式到MCMC算法

- [从一次OJ提交到贝叶斯公式](#从一次oj提交到贝叶斯公式)
  - [从OJ开始——一个小故事](#从oj开始一个小故事)
  - [什么是贝叶斯式的思维？](#什么是贝叶斯式的思维)
    - [频率 vs 贝叶斯——概率是什么？](#频率-vs-贝叶斯概率是什么)
      - [频率学派 vs 贝叶斯学派](#频率学派-vs-贝叶斯学派)
      - [频率学派的观点](#频率学派的观点)
      - [“频率说”看上去不是很完美吗？](#频率说看上去不是很完美吗)
      - [贝叶斯学派的观点](#贝叶斯学派的观点)
    - [为了实践贝叶斯式的思维，我们还需要什么？](#为了实践贝叶斯式的思维我们还需要什么)
      - [什么是先验概率？](#什么是先验概率)
      - [什么是后验概率？](#什么是后验概率)
      - [来点例子](#来点例子)
  - [如何实践贝叶斯式的思维](#如何实践贝叶斯式的思维)
    - [如何重新评估？](#如何重新评估)
      - [猜测与证据不符的情况](#猜测与证据不符的情况)
    - [贝叶斯公式](#贝叶斯公式)
      - [关于穿裤子的是男生还是女生的例子](#关于穿裤子的是男生还是女生的例子)
      - [如何理解贝叶斯公式](#如何理解贝叶斯公式)
- [从拼写纠正到贝叶斯推断](#从拼写纠正到贝叶斯推断)
  - [很多很多次OJ提交——怎么找规律](#很多很多次oj提交怎么找规律)
  - [其他的方法](#其他的方法)
- [从一颗圣诞树有多大到蒙特卡洛方法](#从一颗圣诞树有多大到蒙特卡洛方法)
  - [如何求圣诞树的体积](#如何求圣诞树的体积)
  - [蒙特卡洛（Monte Carlo）方法的起源](#蒙特卡洛monte-carlo方法的起源)
  - [我们到底为什么需要这种方法](#我们到底为什么需要这种方法)
  - [怎么才能正确地“撒豆子”？](#怎么才能正确地撒豆子)
    - [什么是采样](#什么是采样)
    - [直接采样](#直接采样)
    - [更复杂的情况——接受-拒绝采样](#更复杂的情况接受-拒绝采样)
    - [更更更复杂的情况——马尔科夫蒙特卡洛采样](#更更更复杂的情况马尔科夫蒙特卡洛采样)
- [从圣诞老人会不会给你礼物到马尔科夫链](#从圣诞老人会不会给你礼物到马尔科夫链)
  - [圣诞老人今年会不会给你礼物？](#圣诞老人今年会不会给你礼物)
    - [先说个简单点的故事](#先说个简单点的故事)
    - [再复杂一点点](#再复杂一点点)
- [后话](#后话)
  - [参考文献](#参考文献)

## 从一次OJ提交到贝叶斯公式

### 从OJ开始——一个小故事

> 这是一个晴朗的早晨，坐在电脑前的我一遍一遍对着一道 OJ 题的代码的跑着测试。既然是测试，肯定先从简单的值开始，0、1、2，一切好像都很正常；接下来是 -1、-2、100、1000、10000，输出依旧没有什么问题、接下来是 -2,147,483,648‬ 和 2,147,483,648‬ 和 2,147,483,647，竟然依旧没有问题。于是我逐渐**相信**，我的代码没有问题。（尽管绝大多数情况下，提交后依然会在第一个测试点fail）。

### 什么是贝叶斯式的思维？

实际上，之前的小故事中的思维方式就是一种贝叶斯式的思维。让我们回顾一下这个故事。为了确认我的代码没有bug，我做了这几次测试：

1. 一个十分**简单**的样例；
2. 一个**稍微困难**一点的样例；
3. 一个**更困难**的样例；
4. 一个**十分困难**的样例。

每通过一个样例的测试，我对我的代码没有bug的**信任度**都会提高一点，直到最后一次测试通过，我**十分相信**我的代码没有问题。

这个过程牵涉到的思维实质上是在用一个新的**证据**来**更新**自己对于某件事情会/不会发生（在这里就是代码执行不会出现bug）的**信任程度**，这就是贝叶斯推断的思维过程。

#### 频率 vs 贝叶斯——概率是什么？

你可能注意到，在上文中多次出现了“信任程度”、“信任度”、“相信”之类词汇，而且我还加粗了他们。而且，“贝叶斯”不是和**概率**，这个客观的事物相关的吗？怎么就和**“相信”**这个主观的词汇扯上关系了呢？这牵涉到了一个问题，概率究竟是什么？

##### 频率学派 vs 贝叶斯学派

对于概率，描述性的定义一般是这样的：

> 概率，亦称“或然率”，它是反映随机事件出现的可能性（likelihood）大小

公理化的定义一般是这样的：

> 设$E$是随机试验，$S$是它的样本空间。对于E的每一事件$A$赋于一个实数，记为$P(A)$，称为事件$A$的概率。这里$P(A)$是一个集合函数，$P(A)$要满足下列条件：
>
> 1. 非负性：对于每一个事件$A$，有$P(A)≥0$;
> 2. 规范性：对于必然事件，有$P(Ω)=1$;
> 3. 可列可加性：设$A_1, A_2\cdots$是两两互不相容的事件，即对于$i≠j$，$A_i \cap A_j=\varphi(i,j=1,2\cdots)$，则有$P(A_1\cup A_2 \cup \cdots)=P(A_1) + P(A_2) + \cdots$

但是这二者都没有解决一个问题：如何从统计结果**推断**概率。

##### 频率学派的观点

对于这个问题，最直接的一个想法就是从这个事件本身出发，去看他发生的**频率**，再用频率去近似到概率。这也是大多数时候我们看到的、用到的、想到的做法。用数学的语言表达就是：

$$
P(A) = \lim_{N \to \infty} \frac{M}{N} \text{ , 其中} M \text{为} N \text{次实验中} A \text{事件发生的次数}
$$

这很符合直觉啊！要计算某个事件的概率，那我就从**自然**出发，对事件**本身**建模并去**大量地**实验、统计这个事件出现的频数和频率。既然我们人类不知道概率，那就让大自然去帮帮我们好了。

比如，<u>航班晚点</u>的概率，在频率学派地观点下就是<u>航班晚点</u>在大量实验中的**频率**。那么这样子看，推断飞机事实的概率这个工作就十分简单了，直接统计历史的航班数和晚点次数，二者之商就是频率了

##### “频率说”看上去不是很完美吗？

按照这种说法，“频率说”不是很贴近直觉，很有效、很好吗？为什么还会有贝叶斯学派呢？让我们换一个例子来看。

如果我问你**这次**航班晚点的概率是多少呢？直觉上来说，依据频率学派的观点，我们是从之前的航班晚点情况来推断整体的航班晚点的情况，进而再说这次航班晚点的概率等于整体航班晚点的情况。但是，**这次**航班本身只会发生**一次**啊！如果这个例子不够好，那么总统选举呢？世界杯冠军呢？这些事件本身没有**足够的**（相较于频率学派差的很多吧）试验次数，这种时候，频率当然也就不能等于概率。那么，概率又该是什么呢？

##### 贝叶斯学派的观点

贝叶斯学派一方与频率学派一方不同，他们直接从**观测者**一侧去理解概率。概率在贝叶斯学派的语境下被当作一种信任度，这种出于主观的概念。概率被当作一种对于事件发生与否的信任程度的度量。在这个概念中，“不确定”作为概率的一部分依然被保留了下来，而不是像频率学派的概率一样是个确定的值。在贝叶斯的话语下，概率是会根据观测者观测到数据的不断增加而不断调整、改变，最终趋近于“概率”。也就是说，$P(A)=p_i \space (0 \leq p_i \leq 1, i \in \mathbb{N}^*)$ 本身也被认为是一个可能事件，而随着观测到数据变多，$p_i = p_0$时的频率 $P\{P(A)=p_0\}$ 会最终逼近1，而这个$p_0$通常就与频率学派下的概率一致。

以<u>抛硬币的结果是正面</u>这个事件为例。一开始，我们对于抛到正面的概率一无所知（假装如此），我们先认为这个概率是在0到1之间均匀分布的。当我们抛到一次正面时，我们会觉得，可能<u>抛到正面的可能性</u>更大一点。随着抛硬币的次数越来越多，这个可能性会逐渐稳定到0.5。

为了更好的理解，我找到了下面这个例子。实质上，这几张图其实都是**概率分布函数**的图像，只不过刻画的是**概率的概率**（$x=p_i, \space y = P\{P(A)=p_i\}$）。

![download1](.\pic\download1.png)

再来用这个思路解释更多的例子吧！

1. 我的代码可能有bug也有可能没有bug，但是考虑到我的编码能力并且通过测试，我可以选择相信我的代码有bug / 没有bug。
2. 一个病人有症状$x$、$y$、$z$；有很多种疾病都有这些症状，但我们确定这位病人只得了一种病。一位医生可能根据症状$x$、$y$、$z$和他的经验相信这位病人患有某种疾病，尽管另一位医生又不同的想法

可以发现，在贝叶斯的语境下，我们是在不断**学习**某个事件的概率；或者说，在经过某个数据集（对于人类而言，过去的经验）**训练**之后，我们逐渐了解了一个事件的概率。这个概率有多贴近于现实取决于这个数据集的大小（经验的多少）。这个观点实质上更加贴近于我们人类“学习”的过程。

#### 为了实践贝叶斯式的思维，我们还需要什么？

上述的显然只是一些描述性的东西，甚至没有很多的专业名词。为了更好的使用和讨论，我们当然需要了解一下，这些概念在贝叶斯的语境下对应了什么。

##### 什么是先验概率？

对于事件$A$本身可能发生的概率，我们称之为先验概率（Prior Probability），记作$P(A)$。用更为“贝叶斯”的话说，你对于一个猜测本身（或者说，原来）的相信程度，就是先验概率。在这里，“原来”是指没有看到新的证据之前，也可以说是没有经过**这次**学习，或者说训练之前的情况。这也是“先验”这个翻译的原因。（如果“先验”这个词依旧不好理解，可以试着把“先验”换成“经验”。尽管这样在意思上有细微的差距。）

另外，很多时候我们都会将一个猜测作为先验概率中的事件$A$，比如：“我猜测我的代码没有bug”、“那位医生猜测这位病人得了这种疾病”。我们或许可以用$H$，来代表“猜测”（Hypothesis），进而用$P(H)$来代表这个猜测的先验概率。

##### 什么是后验概率？

在经过一次或者很多次观测之后，我们能看到一些新的证据（evidence），我们将这些证据称为$X$。经过这些证据修正过后的概率我们称之为后验概率（Posterior Probability），记作$P(A|X)$。在大多数情况下，我们拿到的新证据都是一些数据（即便不是以数据的方式呈现，我们也可以理解为数据），所以抛开$A$和$X$这种过于随意的字母，我们可以将后验概率写成$P(H | data)$。

##### 来点例子

沿用刚才的那些例子来说，

1. $P(H)$：根据我之前对于我编码水平，我猜测的代码里有bug的概率；$P(H|data)$：经过测试并得到测试结果$data$后，我调整了我对于bug出现的可能性的猜测，我更倾向于认为我的代码里没有bug了，但仍然有一定可能有bug。
2. $P(H)$：医生基于他之前的经验猜测病人得了哪种疾病的猜测；$P(H|data)$：经过检查并得到检查结果$data$后，医生调整了他对于病人患病可能的概率，更为倾向于认为他得了疾病$A$，尽管可能他得的不是疾病$A$。

### 如何实践贝叶斯式的思维

#### 如何重新评估？

根据上面提到的例子，我们会发现，在先验概率到后验概率之间存在着一次“调整”，或者说“更新”（update）。如何完成这个调整就成为了实践贝叶斯推断的关键。

直觉上来说，我们即不会丢弃原有的假设（先验概率），也必然要考虑到新的证据。既然如此，我们就当然会遇到两种截然相反的情况：猜测与证据相符、猜测与证据不符。但是在这里，可以见得，在实践中，我们人类不可能完全猜中，所以基本上也就没有什么完全相符的情况了。

##### 猜测与证据不符的情况

理想状态下，这种情况下随着试验次数$N$不断变多，先验概率对于后验概率的影响会逐渐消失。这是因为我们希望在这个训练的过程中，这个模型可以不断的自我调整，而$N \to \infty$时，给出一个完全贴合现实的后验概率。所以照着这个思路想，只要$N$足够大，不管先验概率给的好不好，后验概率都能贴合到现实情况。

回到之前那个抛硬币的例子，即便换了个不好的开局，最后只要次数够多，依然可以矫正回来（甚至在证据/数据的影响下，后验概率更偏向于投出反面了）。

![Figure_1](.\pic\Figure_1.png)

#### 贝叶斯公式

##### 关于穿裤子的是男生还是女生的例子

让我们从猜测、证据的这个角度回顾一下这个例子。

> 一所学校里面有 60% 的男生，40% 的女生。男生总是穿长裤，女生则一半穿长裤一半穿裙子。有了这些信息之后我们可以容易地计算“随机选取一个学生，他（她）穿长裤的概率和穿裙子的概率是多大”，这个就是前面说的“正向概率”的计算。然而，假设你走在校园中，迎面走来一个穿长裤的学生（很不幸的是你高度近似，你只看得见他（她）穿的是否长裤，而无法确定他（她）的性别），你能够推断出他（她）是男生的概率是多大吗？

我们先将这个问题分成前后两部分（1）迎面走来的一个人是男生的概率（2）迎面走来的一个穿着长裤看的人是男生的概率。在这里，我们将“看到穿着长裤”这个事情作为一个新的证据。于是我们就可以将$P(\text{是男生})$作为先验概率，$P(\text{是男生}|\text{穿着长裤})$作为后验概率。再根据《平凡而又神奇的贝叶斯方法》中的推导过程（尽管大多数时候都是从频率出发的，但是这样子更简单更直觉）我们就有了：

$$
\begin{aligned}

  & P(\text{是男生}|\text{穿着长裤}) \\
= & \frac
    {P(\text{是男生}) * P(\text{穿着长裤}|\text{是男生})}
    {P(\text{是男生}) * P(\text{穿着长裤}|\text{是男生}) + P(\text{不是男生}) * P(\text{穿着长裤}|\text{不是男生})}

\end{aligned}
$$

这就是大名鼎鼎的贝叶斯公式：

$$
P(B|A) = \frac{P(A|B) * P(B)} {P(A|B) * P(B) + P(A|~B) * P(~B)}
$$

用之前的语言来表示就是：

$$
P(H_1|data) = \frac{P(data|H_1) * P(H_1)} {P(data|H_0) * P(H_0) + P(data|~H_0) * P(~H_0)}
$$

其中，$H_1$称为原假设（Null Hypothesis），$H_0$称为备择假设（Alternative Hypothesis）。这两个名称的意思就是它的字面意思，翻译的可以说很不错了。

##### 如何理解贝叶斯公式

这个公式，用直觉来解释就是：建立在一个观测到的数据（或者说，证据）上的一个猜测值不值得相信，取决于“这个猜测本身能不能说服你 / 你值不值得相信（先验概率）”和“这个猜测生成我们观察到的证据的可能性大小”（似然，Likelihood）的乘积。具体到我们的那个 有没有bug的例子上，含义就是，实际上有bug的可能性大小取决于 bug本身出现的可能性（我的编码水平）大小（先验概率）和 经过测试后有bug的可能性大小（似然）的乘积。


## 从拼写纠正到贝叶斯推断

### 很多很多次OJ提交——怎么找规律

我粗略的看了一下我一年以来的OJ提交情况，下图展示了我再通过所有测试前的错误次数。

![image-20191230192835831](D:\MyDocument\NutstoreDatabase\MyFile\From Bayes To MCMC\pic\image-20191230192835831.png)

（横坐标其实应该是$[m,n)$，都怪Excel）



看到这张图，我们可能会不自觉的想，这有什么规律吗？如果好！我们就来看看这又什么规律。

首先，大胆地猜测这个错误次数$Err_i$符合泊松分布，即：

$$
Err_i \sim \rm{Poi}(\lambda_i)
$$

我们目前还看不出来$\lambda$的确切的值，但是根据上面那张图，大致的峰值有两个，一个是在$[0,1)$，一个是在$[4,6)$。于是，我们可以猜测在某个点$\tau$处，泊松分布的参数发生了一次变化。也就是说，我们实际上由两个$\lambda$，一个是$\tau$之前的，一个是$\tau$之后的。也就是：

$$
\lambda = 
\begin{cases}
\lambda_1,  & \text{if } s < \tau \\[2ex]
\lambda_2, & \text{if }  s \ge \tau
\end{cases}
$$

现在我们的目标就变成了推测出这两个为止的$\lambda$。为了使用贝叶斯推断，我们需要一个$\lambda$的先验概率。注意到这两个$\lambda$都是正数，所以我们就大胆地（武断的）假设他们都服从指数分布吧！其实无论怎么样假设这个先验概率都没有关系，如果在这点上有疑问，你可以往前翻一翻，我们讨论过这个问题。所以其实很可能有更好的模型，但是这在目前并不重要。我们就简单的设指数分布的参数为$\alpha$吧。这个式子看起来会是这样：
$$
\lambda_1 \sim \rm{Exp}(\alpha)
$$

$$
\lambda_2 \sim \rm{Exp}(\alpha)
$$

最后再来取一个$\tau$的模型，这里我同样武断地认为它服从指数分布，这次让我们把参数叫成$\beta$吧：
$$
\tau \sim \rm{Exp}(\beta)
$$
好了，现在我们已经完成了所有的预备工作，我们有了数据，有了先验概率，接下来只要计算后验概率就好了。但是说实话，在这里我并不是很乐意介绍这个过程（太复杂了，而且我们有计算机XD）。所以，让我们直接继续吧。

### 其他的方法

就用拼写纠正的例子来说：

> 比如用户输入： thew ，那么他到底是想输入 the ，还是想输入 thaw ？到底哪个猜测可能性更大呢？幸运的是我们可以用贝叶斯公式来直接出它们各自的概率，我们不妨将我们的多个猜测记为 h1 h2 .. （ h 代表 hypothesis），它们都属于一个有限且离散的猜测空间 H （单词总共就那么多而已），将用户实际输入的单词记为 D （ D 代表 Data ，即观测数据）。

在这里，我们除了使用贝叶斯的方法（具体过程可以直接去看《平凡而又神奇的贝叶斯方法》），也可以考虑最为可能的方法，也就是只考虑贝叶斯公式中的“似然”，找一个“最大似然”的解。放到之前那个例子来说，只要你愿意，我们可以找一个多项式来你和这些点，而且可以完美的拟合上，但是……让我们直接来看吧。

这是用六次多项式拟合的情形，其实即便是这样可以看到拟合的已经很不错了。


![image-20191230223219373](C:\Users\zcspo\AppData\Roaming\Typora\typora-user-images\image-20191230223219373.png)

但是！如果把这个函数往后延一点就能发现：

![image-20191230223521617](C:\Users\zcspo\AppData\Roaming\Typora\typora-user-images\image-20191230223521617.png)

这根本不是我们想要的结果吗！所以，除了“过配”和超级复杂的计算（当数据点很多的时候，也就是几乎全部时候），这样子的方法很有可能不能帮我们“预测”一些趋势，而是单纯的只能照顾到现有的数据。

## 从一颗圣诞树有多大到蒙特卡洛方法

### 如何求圣诞树的体积

Merry  Christmas! 圣诞节到了，圣诞树又变得到处都有了，但是有没有想过，如何计算一颗圣诞树的体积呢？（不许用排液法！圣诞树浸水了还怎么用！）

<img src=".\pic\2.png" alt="2" style="zoom: 15%;" />

方便起见，我们先来考虑一颗二维世界的圣诞树的面积：

<img src=".\pic\55890f7547515e6964fbc72e16994668.jpg" alt="55890f7547515e6964fbc72e16994668" style="zoom:50%;" />

你当然可以去算一个很长很长很长很长的多项式，然后做一个很难很难很难很难的积分来求出这个面积，只要你愿意XD。那么有没有什么简单点的方法呢？

我们再把维度拍扁到一维，考虑一颗一维世界的圣诞树。

![image-20191230225705206](.\pic\image-20191230225705206.png)

我们如何计算这颗圣诞树的长度呢？给一点提示，如果我们在这条黑线上随机取一个点，这个点落在绿色范围内的概率我们会如何计算呢？Bingo！$P\{\text{点落在圣诞树内}\}=\text{圣诞树的长度}/\text{总长度}$，所以，反过来，如果要计算圣诞树的长度，我们就可以先随机在这个范围内取一堆点，然后看看$P\{\text{点落在圣诞树内}\}$，最后再$P{\text{点落在圣诞树内}}*\text{总长度}$就有了圣诞树的长度。

推展到二维世界，我们甚至可以更轻松的完成这个任务。在地上勾勒出一个圣诞树的轮廓，再在轮廓外画一个知道大小的矩形/圆形，往地上倒一大堆豆子，最后再数一数落在范围内的豆子的数量和总的豆子数量这件事情就成了。

同样的，这个思路在三维世界肯定也是成立的，只不过我们没法在三维世界那么轻松的撒豆子就是了。

### 蒙特卡洛（Monte Carlo）方法的起源

20世纪40年代，在冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时，发明了蒙特卡罗方法。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡洛赌场输钱得名，而蒙特卡罗方法正是以概率为基础的方法。大家也别把蒙特卡洛当一个城市，估计和北京的一条街差不了多少，因为摩纳哥（不是非洲的摩洛哥）本身就是个袖珍国家，比我国澳门都小的多。嗯，在看到这里之前我一直以为蒙特卡洛是个名。说明该方法与赌博中的随机性、概率性有着天然而密切的联系。几乎涉及到复杂的、与概率相关的数值计算的领域都有可能会用到。比如计算物理、经济金融、统计学、机器学习等。

蒙特卡洛没有什么高深的理论，它只是一种方法或者说策略。蒙特卡洛方法并没有什么高深的理论支撑，如果一定要说有理论也就只有概率论或统计学中的大数定律了。基本上甚至可以说是“面向直觉”了。蒙特卡洛的基本原理简单描述是先大量模拟，然后计算一个事件发生的次数，再通过这个发生次数除以总模拟次数，得到想要的结果。

### 我们到底为什么需要这种方法

随着计算机的发展，随机投点并统计这个事情变得逐渐简单，但是一些大规模计算依旧没有变快（比如算个很难很难的积分），所以蒙特卡洛方法这个**统计模拟**方法就逐渐登上舞台了。

### 怎么才能正确地“撒豆子”？

#### 什么是采样

注意了，从现在开始，我们的思维要更“计算机”一点。毕竟就像之前说的，蒙特卡罗方法基本上都是用计算机跑的。“撒豆子”用数学一点的话来说，就是采样。只不过在直觉上，“采样”和“撒豆子”好像是两个方向的事情，前者是从什么地方来到我这里，一个是我把东西扔到什么地方去。在这里，我们更应该相信的直觉应该是“随机取点”——从一个范围内根据一个随机数取一个点。

#### 直接采样

顾名思义，就是直接进行采样咯。这个名字主要是因为在很多相关的库中都内置了一些分布函数，可以直接调用这些来进行采样。

#### 更复杂的情况——接受-拒绝采样

在更多的问题下，我们的目标可能都没法直接采到样本 $p(x)$（库没有这个函数），这就需要我们间接地取采样。首先我们需要一个基础的分布（建议分布，Proposal Distribution）$q(x)$，为了方便我们也可以给这个分布乘以一个常数$k$，然后再用$q(x)$去检验这个抽样结果，如果符合就留下（接受），不符合就扔掉（拒绝）。

![img](https://img-blog.csdn.net/20180723152828496?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMwMjkxMzM1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

结合这张图说，我们首先会抽取一个蓝线下的样本（灰色区域+白色区域），然后去检验它在不在白色区域内，在的会就接受，不在就拒绝。

#### 更更更复杂的情况——马尔科夫蒙特卡洛采样

看名字就知道，这个会一会再说。



## 从圣诞老人会不会给你礼物到马尔科夫链

### 圣诞老人今年会不会给你礼物？

#### 先说个简单点的故事

> 这里的“你”是一个整体的概念，没有冒犯任何一个个人的意思。

假设你是去年一直是一个好孩子，但是今年有20%的概率圣诞老人会觉得你变成一个不乖的孩子而不给你礼物。同时，如果去年圣诞老人觉得你不乖，那么你有50%的概率在今年洗心革面做一个好孩子而得到圣诞老人的礼物。这个转换的图就像是这样：

 ![未命名文件](D:\MyDocument\download\未命名文件.png)

嗯，这就是马尔科夫链了。

#### 再复杂一点点

用数学一点的语言来说，这个过程可以用这个矩阵来表示：

$$
P=
\left[
 \begin{matrix}
  0.8 & 0.2 \\
  0.5 & 0.5
 \end{matrix}
\right]
$$

当你在这个状态图中走了$n$次时的概率分布用$x^{(n)}$表示，比如，假设你一开始是个好孩子，即 $x^{(0)}=[ \begin{matrix}0 &1\end{matrix}]$，进而（如果了解离散数学的话），$x^{(n)}=x^{(0)}P^n$。我们可以尝试着计算一下随着$n$增加时$P^n$的情况：

$$
\begin{aligned}
  & P^1=
  \left[
  \begin{matrix}
    0.74 & 0.26 \\
    0.65 & 0.35
  \end{matrix}
  \right]
  
  \\

  & P^2=
  \left[
  \begin{matrix}
    0.74 & 0.26 \\
    0.65 & 0.35
  \end{matrix}
  \right]

  \\

  & P^3=
  \left[
  \begin{matrix}
    0.7166 & 0.2834 \\
    0.7085 & 0.2915
  \end{matrix}
  \right]

  \\

  & \vdots
  
  \\

  & P^{48}=
  \left[
  \begin{matrix}
    0.7145 & 0.2857 \\
    0.7145 & 0.2857
  \end{matrix}
  \right]
  
  \\

  & P^{49}=
  \left[
  \begin{matrix}
    0.7145 & 0.2857 \\
    0.7145 & 0.2857
  \end{matrix}
  \right]
  
  \\

  & P^{50}=
  \left[
  \begin{matrix}
    0.7145 & 0.2857 \\
    0.7145 & 0.2857
  \end{matrix}
  \right]
\end{aligned}
$$
不断地迭代后可以发现，转换矩阵逐渐稳定到了一个状态上，即，收敛了。这件事情也是直观的和经验的（许多地方都没有给出证明，说是因为很复杂）。

## 后话

原来在这一部分想写到MCMC方法的具体内容，但是囿于时间精力，（主要是暂时学不会），就没有写。（连题目都想好了，叫“当圣诞树遇上圣诞老人——MCMC”）蒙特卡洛和马尔科夫链的部分写的也十分的仓促。这个作业确实push我做了一些事情，尤其是最早的贝叶斯公式那一块，刷新了我对于贝叶斯的认识。我有一种预感——过一段时间，当我开始学习机器学习相关的内容的时候，我会回来，再把这些参考文献列表里的文章再仔仔细细地看一遍。

### 参考文献

https://nbviewer.jupyter.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/tree/master/

http://mindhacks.cn/2008/09/21/the-magical-bayesian-method/

https://blog.csdn.net/qq_30291335/article/details/81168167

https://www.cnblogs.com/pinard/p/6625739.html

https://mp.weixin.qq.com/s?__biz=MzAxMDA4NjU3OA==&mid=208295028&idx=1&sn=d22dea627fff86bf0daded79959bd019&scene=21#wechat_redirect

https://en.wikipedia.org/wiki/Monte_Carlo_method

https://www.jiqizhixin.com/graph/technologies/c84b6d7e-447f-4bcb-b4a5-c807d7b8a5f7

《LDA数学八卦》

《From Algorithms to Z-Scores: Probabilistic and Statistical Modeling in Computer Science》